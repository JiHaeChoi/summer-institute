{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Site Scaffold Generator\n",
    "\n",
    "This script generates site and data directories from templates, replacing placeholder tags\n",
    "with values from a CSV file.\n",
    "\n",
    "Required Setup:\n",
    "-------------\n",
    "1. Create a 'sites.csv' file in the same directory as this notebook with the following columns:\n",
    "   - YEAR: The year of the event (e.g., 2025)\n",
    "   - NAME: URL-friendly name of the event (e.g., ucla, and NOT \"SICSS-ucla\")\n",
    "   - LOCATION: Physical location of the event (e.g., Berkeley California)\n",
    "   - START_DATE: Event start date in format \"Month Day\" (e.g., \"August 1\")\n",
    "   - END_DATE: Event end date in format \"Month Day\" (e.g., \"August 15\")\n",
    "   - HOST: hosting institution / department (e.g., The UCLA Social Media Research Lab)\n",
    "\n",
    "Order of the columns should not matter. Populate with data from form sent to organizers, or with manually inputted data. This should still save you a bit of time!\n",
    "\n",
    "Note: if you are creating the first site(s) for a given year, you will have to go to the _config.yml file in the base directory of the repo, and update the \"current_year\" parameter so that the locations appear in the locations page and have a tab.\n",
    "\n",
    "Note 2: if a site has adjusted their naming from year to year, but you still want it to appear as a continuation of that site here, you may need to adjust the name you have in your csv file to match the old one, or go back and rename folders / change the md and yml where necessary if you notice later.\n",
    "\n",
    "Example CSV row:\n",
    "2025,ucla,\"Berkeley, California\",August 1,August 15\n",
    "\n",
    "The script will:\n",
    "- Create year folders if they don't exist\n",
    "- Copy templates from .20XX_template/[[NAME]]/ to /YEAR/NAME/\n",
    "- Copy templates from /_data/.template/[[NAME]]/ to /_data/YEAR/NAME/\n",
    "- Replace all [[TAG]] patterns in .md and .yml files with corresponding CSV values\n",
    "- Attempt to find and apply a header / location browse image from previous years of the same location\n",
    "\n",
    "Usage:\n",
    "    run the below cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_path_name(name):\n",
    "    accent_map = {\n",
    "        'ü': 'u', 'ä': 'a', 'ö': 'o',\n",
    "        'é': 'e', 'è': 'e', 'ê': 'e', 'ë': 'e',\n",
    "        'á': 'a', 'à': 'a', 'â': 'a', 'ã': 'a',\n",
    "        'í': 'i', 'ì': 'i', 'î': 'i', 'ï': 'i',\n",
    "        'ó': 'o', 'ò': 'o', 'ô': 'o', 'õ': 'o',\n",
    "        'ú': 'u', 'ù': 'u', 'û': 'u',\n",
    "        'ý': 'y', 'ÿ': 'y',\n",
    "        'ñ': 'n', 'ç': 'c'\n",
    "    }\n",
    "    \n",
    "    path_name = str(name).lower()\n",
    "    for accent, replacement in accent_map.items():\n",
    "        path_name = path_name.replace(accent, replacement)\n",
    "    return re.sub(r'[^a-z0-9]', '-', path_name)\n",
    "\n",
    "def find_most_recent_image(root_dir, current_year, location_name):\n",
    "    \"\"\"Find the most recent header image for a given location from previous years.\"\"\"\n",
    "    # Convert current_year to int for comparison\n",
    "    current_year = int(current_year)\n",
    "    \n",
    "    # Check all previous years in descending order\n",
    "    for year in range(current_year - 1, 2016, -1):  # 2016 being the earliest SICSS year\n",
    "        # Check both possible image locations\n",
    "        data_image = root_dir / '_data' / str(year) / location_name / 'location.yml'\n",
    "        site_image = root_dir / str(year) / location_name / 'index.md'\n",
    "        \n",
    "        # Check data image first\n",
    "        if data_image.exists():\n",
    "            with open(data_image, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                image_match = re.search(r'^image:\\s*(.+)$', content, re.MULTILINE)\n",
    "                if image_match and 'tbd.jpg' not in image_match.group(1):\n",
    "                    return image_match.group(1).strip()\n",
    "        \n",
    "        # Then check site image\n",
    "        if site_image.exists():\n",
    "            with open(site_image, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                image_match = re.search(r'^image:\\s*(.+)$', content, re.MULTILINE)\n",
    "                if image_match and 'tbd.jpg' not in image_match.group(1):\n",
    "                    return image_match.group(1).strip()\n",
    "    \n",
    "    # Return default if no previous image found\n",
    "    return '/assets/images/tbd.jpg'\n",
    "\n",
    "def replace_tags_in_file(file_path, replacements):\n",
    "    # Get root directory\n",
    "    root_dir = Path.cwd().parent\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Create path-friendly name for links and directories\n",
    "    path_name = path_name = clean_path_name(replacements['NAME'])\n",
    "    \n",
    "    # Find previous year's image if it exists\n",
    "    previous_image = find_most_recent_image(root_dir, replacements['YEAR'], path_name)\n",
    "    \n",
    "    # Special handling for YAML files and YAML front matter\n",
    "    is_yaml = file_path.suffix == '.yml'\n",
    "    \n",
    "    if is_yaml:\n",
    "        # Handle location.yml specially to update the image\n",
    "        if file_path.name == 'location.yml':\n",
    "            content = re.sub(r'^image:\\s*.*$', f'image: {previous_image}', \n",
    "                           content, flags=re.MULTILINE)\n",
    "            \n",
    "        # Handle hero.yml specially\n",
    "        if file_path.name == 'hero.yml':\n",
    "            # Use original NAME value for location field\n",
    "            content = re.sub(r'^location:\\s*.*$', f'location: SICSS-{replacements[\"NAME\"]}', \n",
    "                           content, flags=re.MULTILINE)\n",
    "            \n",
    "            # Handle other replacements normally\n",
    "            for tag, value in replacements.items():\n",
    "                if tag != 'NAME':  # Skip NAME as we handled it specially\n",
    "                    pattern = f'\\\\[\\\\[{tag}\\\\]\\\\]'\n",
    "                    content = re.sub(pattern, str(value), content, flags=re.IGNORECASE)\n",
    "        else:\n",
    "            # For other YAML files, use path_name only for 'link:' field\n",
    "            content = re.sub(r'^link:\\s*.*$', f'link: {path_name}', content, flags=re.MULTILINE)\n",
    "            \n",
    "            # Handle all replacements in YAML files\n",
    "            for tag, value in replacements.items():\n",
    "                pattern = f'\\\\[\\\\[{tag}\\\\]\\\\]'\n",
    "                \n",
    "                # Use original NAME value for title field\n",
    "                if tag == 'NAME':\n",
    "                    content = re.sub(r'^title:\\s*.*$', f'title: {value}', content, flags=re.MULTILINE)\n",
    "                    # Use path_name for other NAME instances (except title)\n",
    "                    content = re.sub(pattern, path_name, content, flags=re.IGNORECASE)\n",
    "                else:\n",
    "                    content = re.sub(pattern, str(value), content, flags=re.IGNORECASE)\n",
    "    else:\n",
    "        # Update image in index.md\n",
    "        if file_path.name == 'index.md':\n",
    "            content = re.sub(r'^image:\\s*.*$', f'image: {previous_image}', \n",
    "                           content, flags=re.MULTILINE)\n",
    "        \n",
    "        # Handle YAML front matter in markdown files\n",
    "        yaml_pattern = r'^---\\n.*?---'\n",
    "        def yaml_replacer(match):\n",
    "            yaml_content = match.group(0)\n",
    "            # Use original NAME value for title field in front matter\n",
    "            yaml_content = re.sub(r'^title:\\s*.*$', f'title: {replacements[\"NAME\"]}', \n",
    "                                yaml_content, flags=re.MULTILINE)\n",
    "            # Use path_name only for partner_site field\n",
    "            yaml_content = re.sub(r'^partner_site:\\s*.*$', f'partner_site: {path_name}', \n",
    "                                yaml_content, flags=re.MULTILINE)\n",
    "            # Remove any remaining [[NAME]] tags in front matter\n",
    "            yaml_content = re.sub(r'\\[\\[NAME\\]\\]', path_name, yaml_content, flags=re.IGNORECASE)\n",
    "            return yaml_content\n",
    "        \n",
    "        content = re.sub(yaml_pattern, yaml_replacer, content, flags=re.DOTALL)\n",
    "        \n",
    "        # Handle the rest of the content - use original NAME value\n",
    "        for tag, value in replacements.items():\n",
    "            pattern = f'\\\\[\\\\[{tag}\\\\]\\\\]'\n",
    "            content = re.sub(pattern, str(value), content, flags=re.IGNORECASE)\n",
    "    \n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def generate_scaffolds(csv_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Get the root directory\n",
    "    root_dir = Path.cwd().parent\n",
    "    \n",
    "    # Define template directories\n",
    "    template_dir = root_dir / '.20XX_template'\n",
    "    data_template_dir = root_dir / '_data' / '.template'\n",
    "    \n",
    "    # Track which years we've already processed\n",
    "    processed_years = set()\n",
    "    \n",
    "    # Process each row in the CSV\n",
    "    for _, row in df.iterrows():\n",
    "        year = str(row['YEAR'])\n",
    "        name = str(row['NAME'])\n",
    "\n",
    "        path_name = clean_path_name(name)\n",
    "        \n",
    "        # Create replacements dictionary from CSV columns\n",
    "        replacements = {col: str(value) for col, value in row.items()}\n",
    "        \n",
    "        # Create year directories if they don't exist\n",
    "        year_dir = root_dir / year\n",
    "        year_dir.mkdir(exist_ok=True)\n",
    "        (root_dir / '_data' / year).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy and process index.md for new year folders\n",
    "        if year not in processed_years:\n",
    "            index_source = template_dir / 'index.md'\n",
    "            index_target = year_dir / 'index.md'\n",
    "            shutil.copy2(index_source, index_target)\n",
    "            replace_tags_in_file(index_target, replacements)\n",
    "            processed_years.add(year)\n",
    "        \n",
    "        # Check for existing directories and skip if found\n",
    "        target_dir = year_dir / path_name\n",
    "        data_target_dir = root_dir / '_data' / year / path_name\n",
    "        \n",
    "        if target_dir.exists() or data_target_dir.exists():\n",
    "            print(f\"Warning: Skipping {year}/{path_name} - directory already exists\")\n",
    "            continue\n",
    "            \n",
    "        # Create main site scaffold\n",
    "        shutil.copytree(template_dir / '[[NAME]]', target_dir)\n",
    "        \n",
    "        # Create data scaffold\n",
    "        shutil.copytree(data_template_dir / '[[NAME]]', data_target_dir)\n",
    "        \n",
    "        # Replace tags in all files in both directories\n",
    "        for dir_path in [target_dir, data_target_dir]:\n",
    "            for file_path in dir_path.rglob('*'):\n",
    "                if file_path.is_file() and file_path.suffix in ['.md', '.yml']:\n",
    "                    replace_tags_in_file(file_path, replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping 2025/amu-law - directory already exists\n",
      "Warning: Skipping 2025/penn - directory already exists\n",
      "Warning: Skipping 2025/acdam - directory already exists\n",
      "Warning: Skipping 2025/nyu-shanghai - directory already exists\n",
      "Warning: Skipping 2025/fgv-ecmi-brazil - directory already exists\n",
      "Warning: Skipping 2025/ias - directory already exists\n"
     ]
    }
   ],
   "source": [
    "generate_scaffolds('sites.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test csv file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can be used to generate testing data for this script.\n",
    "\n",
    "data = {\n",
    "    'YEAR': [2029, 2029, 2029, 2029, 2029],\n",
    "    'NAME': ['winter-festival', 'spring-market', 'summer-fair', 'autumn-expo', 'holiday-bazaar'],\n",
    "    'LOCATION': ['Central Park', 'Downtown Plaza', 'Riverside Park', 'Convention Center', 'Main Street'],\n",
    "    'START_DATE': ['December 1', 'March 15', 'June 20', 'September 5', 'December 10'],\n",
    "    'END_DATE': ['December 15', 'March 30', 'June 25', 'September 10', 'December 20']\n",
    "}\n",
    "\n",
    "df_test = pd.DataFrame(data)\n",
    "# df_test.to_csv('sites.csv', index=False)  # uncomment this if you want it to save "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
